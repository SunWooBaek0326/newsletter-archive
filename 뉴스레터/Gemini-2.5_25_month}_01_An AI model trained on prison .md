---
created: 2025-12-01 // Date 객체를 사용하여 날짜 생성
tags:
  - newsletter
  - gemini
source: "https://www.technologyreview.com/2025/12/01/1128591/an-ai-model-trained-on-prison-phone-calls-is-now-being-used-to-surveil-inmates/"
model: Gemini-2.5
---

# An AI model trained on prison phone calls now looks for planned crimes in those calls

# 현실판 '마이너리티 리포트'? 7년 치 수감자 통화 기록을 학습한 AI의 등장

### Editor’s Note: '생각'을 감시하는 기술이 도래했다
영화 <마이너리티 리포트>에서는 범죄가 일어나기 전, 이를 미리 예측해 예비 범죄자를 체포하는 '프리크라임(Pre-crime)' 시스템이 등장합니다. 오랫동안 SF의 영역에 머물러 있던 이 개념이 거대언어모델(LLM)과 방대한 데이터를 만나 현실의 영역으로 들어오고 있습니다.

미국의 한 통신 기업이 수감자들의 수년 치 통화 데이터를 AI에 학습시켜, 범죄 모의를 실시간으로 탐지하는 시스템을 가동하기 시작했습니다. 단순한 키워드 감지가 아닙니다. AI는 문맥을 읽고, 은어를 해석하며, 심지어 범죄가 **"고려되고 있는(contemplated)"** 단계까지 파악하려 합니다. 기술 발전이 법과 윤리를 앞지르고 있는 지금, 이 기술이 감시 사회에 던지는 파장은 무엇일까요?

---

### Deep Dive 1: 텍스트 너머 '의도'를 읽는 AI
미국의 교정 시설 통신 서비스를 제공하는 **시큐러스 테크놀로지스(Securus Technologies)**는 2023년부터 자사가 보유한 방대한 통화 녹음 데이터를 AI 학습에 활용하기 시작했습니다.

이들이 구축한 AI 모델의 핵심은 '규모'와 '깊이'입니다.
*   **데이터의 규모:** 텍사스 교도소 시스템에서만 추출한 7년 치의 통화 기록이 단일 모델 학습에 사용되었습니다. 이외에도 문자 메시지, 이메일 등 교정 시설 내에서 발생하는 거의 모든 커뮤니케이션 데이터가 AI의 먹이가 되었습니다.
*   **작동 방식:** 과거의 감시 시스템이 특정 단어(예: "마약", "탈옥")를 기계적으로 걸러냈다면, 시큐러스의 LLM은 대화의 맥락을 분석합니다. 케빈 엘더(Kevin Elder) 시큐러스 사장은 이를 두고 "범죄가 실제로 실행되기 전, 단지 생각하거나 계획하는 단계에서부터 이를 감지하고 이해할 수 있다"고 설명합니다.

현재 이 시스템은 재판을 기다리는 구치소, 형이 확정된 교도소, 이민세관단속국(ICE) 구금 시설 등에서 시범 운영되고 있습니다. AI가 대화 내용을 분석해 '위험 징후'가 있는 부분을 플래그(Flag)하면, 인간 요원이 이를 검토하고 수사관에게 전달하는 하이브리드 감시 체계입니다. 회사 측은 이 기술이 교도소 내 갱단 활동이나 인신매매 모의를 사전에 차단하는 데 기여했다고 주장합니다.

![Prison Phone Wire](https://wp.technologyreview.com/wp-content/uploads/2025/11/prison-phone-wire.jpg)

### Deep Dive 2: 강요된 동의와 데이터 주권의 상실
기술적 성취 뒤에는 심각한 윤리적 딜레마가 자리 잡고 있습니다. 가장 큰 쟁점은 **'동의(Consent)'의 성격**입니다.

수감자와 통화 상대방은 "이 통화는 녹음됩니다"라는 안내 메시지를 듣습니다. 하지만 **"이 대화가 AI 모델 학습에 사용되어, 미래의 감시 도구를 정교하게 만드는 데 쓰입니다"**라는 사실은 고지받지 못합니다. 시민단체 워스 라이즈(Worth Rises)의 비앙카 타일렉(Bianca Tylek) 대표는 이를 **"강요된 동의(Coercive Consent)"**라고 정의합니다.

> "가족과 소통할 수 있는 유일한 수단이 그것뿐이라면, 선택의 여지가 없습니다. 수감자들은 자신의 데이터를 제공하는 대가로 보상을 받기는커녕, 오히려 비싼 통화료를 지불하며 자신의 데이터를 감시 기업에 넘겨주고 있는 셈입니다."

더욱이 시큐러스는 과거 수감자와 변호인 간의 '비밀 유지 특권(Attorney-Client Privilege)'이 적용되는 통화까지 불법적으로 녹음해 유출된 전력이 있습니다. 시민자유연맹(ACLU)은 이러한 AI 시스템이 도입되면 "모든 발화와 생각까지 감시당하는" 전례 없는 인권 침해가 발생할 수 있다고 경고합니다. 법이 기술의 속도를 따라가지 못하는 사이, 수감자들은 거대한 AI 실험실의 데이터 소스로 전락했습니다.

### Deep Dive 3: 감시 비용은 누가 지불하는가? (규제와 비즈니스)
이 논란은 기술을 넘어 정치와 자본의 문제로 확장됩니다. 핵심은 **"이 고도화된 감시 시스템 구축 비용을 누가 낼 것인가"**입니다.

2024년, 미국 연방통신위원회(FCC)는 교정 시설의 보안 및 감시 비용을 수감자 통화료에 전가하는 행위를 금지하는 개혁안을 내놓았습니다. 이는 수감자 가족들의 경제적 부담을 줄이기 위한 조치였습니다.

하지만 정치 지형이 바뀌며 상황은 역전되었습니다. 
1.  **반발과 로비:** 보안관 협회와 통신 기업들은 "자금이 없으면 모니터링을 할 수 없다"며 강력히 반발했고, 시큐러스는 FCC를 상대로 집요한 로비를 펼쳤습니다.
2.  **정책의 회귀:** 트럼프 행정부 하에서 임명된 브렌던 카(Brendan Carr) FCC 위원장은 2024년의 개혁안을 사실상 무력화했습니다. 그는 2024년의 개혁이 "공공 안전 도구의 도입을 저해한다"며, AI 감시 기술 도입 비용을 수감자 요금에 포함할 수 있도록 길을 열어주었습니다.
3.  **최종 결정:** 결국 2025년 10월, FCC는 통신사들이 AI 분석 도구 개발 및 운영 비용을 수감자에게 전가할 수 있도록 허용하는 새로운 규칙을 통과시켰습니다.

결과적으로, 수감자와 그 가족들은 자신들을 감시하고, 잠재적 범죄를 '예측'하는 AI를 개발하는 비용까지 직접 지불해야 하는 아이러니한 상황에 놓이게 되었습니다.

---

### Takeaway: 기술이 법보다 빠를 때 생기는 일

이번 시큐러스의 사례는 단순히 미국 교도소 내의 인권 문제로만 국한되지 않습니다. 이는 **AI 기술이 공공 영역, 특히 치안과 감시 분야에 도입될 때 발생할 수 있는 미래의 축소판**입니다.

우리가 주목해야 할 시사점은 세 가지입니다.

1.  **데이터 학습의 투명성:** '서비스 이용을 위한 녹음 동의'가 'AI 학습을 위한 데이터 제공 동의'와 동일시될 수 있는지에 대한 사회적 합의가 부재합니다.
2.  **예측적 정의(Predictive Justice)의 위험성:** 행동이 아닌 '생각'이나 '대화의 맥락'만으로 범죄 가능성을 판단하는 기술은 오남용될 소지가 매우 큽니다. AI가 특정 집단이나 은어를 범죄 징후로 잘못 학습할 경우, 편향된 알고리즘이 무고한 사람을 용의자로 지목할 수 있습니다.
3.  **비용의 주체:** 고도화된 테크 솔루션의 비용을 '수익자 부담 원칙'이라는 명목하에 사회적 약자에게 전가하는 비즈니스 모델이 정책적으로 용인되고 있다는 점입니다.

AI는 분명 범죄 예방의 효율성을 획기적으로 높일 잠재력이 있습니다. 하지만 그 효율성이 '최소한의 인권'과 '적법한 절차'라는 민주주의의 가치를 훼손하지 않도록, 기술 도입 속도에 맞는 법적 안전장치 마련이 시급해 보입니다. 한국의 리걸테크 및 보안 산업계 역시 이 논쟁을 주의 깊게 지켜봐야 할 때입니다.